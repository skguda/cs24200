Jupyter NotebookLab11 Last Checkpoint: 11/18/2020 (autosaved)Python 3 [3.6]
Python 3 [3.6] 
File
Edit
View
Insert
Cell
Kernel
Widgets
Help

Markdown
Word Count using Local Map+Reduce¶
You are given an input file. The format of the file is: doc_id \t sentence. The words in the sentence are separated by a whitespace character (' '). To compare the values, you can use the provided file 'documents.txt'. We will use a separate test file with the same format as above, to test your code.

Convert each sentence into lowercase and split into words. You can assume that the words are separated by a whitespace character (' ').
Calculate the frequency of each word across all the documents.
Q1: Mapper function
Write a mapper function that takes a list of sentences as input and outputs a list of (key, value) pairs, such that the key is a word and value is 1.

# mapper(listOfSentences) takes as input a list Of sentences (stings), converts each sentence into lowercase and 
# splits each sentence into words. The function returns the output as a list of tuples with:
# first element (key) as the word
# second element (value) as 1
​
#import re
def mapper(filename):
    
    ###
    ### YOUR CODE HERE
    ### 
    file = open(filename, 'r')  
    line_list = []  
    word_list = []
    for line in file:   
        line_list.append(line.strip().lower()) 
   
    for line in line_list:  
        line = line.strip()
    # split the line into words
        words = line.split()
    # increase counters
        for word in words:
            #print('%s\t%s' % (word, 1)) 
            if(word.isalpha()):  
                word_list.append((word, 1)) 
     
    
    return(word_list)
                
        
     
  
​
​
  
# Example 
# 
# input: documents.txt
# 
# output = [('the', 1), ('quick', 1), ('brown', 1), ('fox', 1), ('jumped', 1), ('over', 1), ('the', 1), 
# ('lazy', 1), ('grey', 1), ('dogs', 1), ('that', 1), ('is', 1), ('one', 1), ('small', 1), ('step', 1), 
# ('for', 1), ('a', 1), ('man', 1), ('but', 1), ('one', 1), ('giant', 1), ('leap', 1), ('for', 1), ('mankind', 1)]
mapper("documents.txt")
[('the', 1),
 ('quick', 1),
 ('brown', 1),
 ('fox', 1),
 ('jumped', 1),
 ('over', 1),
 ('the', 1),
 ('lazy', 1),
 ('grey', 1),
 ('dogs', 1),
 ('that', 1),
 ('is', 1),
 ('one', 1),
 ('small', 1),
 ('step', 1),
 ('for', 1),
 ('a', 1),
 ('man', 1),
 ('but', 1),
 ('one', 1),
 ('giant', 1),
 ('leap', 1),
 ('for', 1),
 ('mankind', 1)]
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
Q2: Combiner function
Write a combiner function that takes the output of the mapper function as input and outputs a dictionary with the key as a word and value as a list of counts for the word.

# combiner(mapper_output) takes as input the output of the mapper function, and returns the output as 
# a dictionary with the key as a word and value as a list of counts for the word.
​
​
def combiner(mapper_output):
    
    ###
    ### YOUR CODE HERE
    ### 
    mdict = {} 
    #print(mapper_output) 
    for pair in mapper_output: 
        if(pair[0] not in mdict):
            mdict[pair[0]] = [1]  
        else: 
            mdict[pair[0]].append(1)# = mdict[pair[0]].append() 
    
    
    return(mdict)
    
    
# Example 
# 
# input: [('the', 1), ('quick', 1), ('brown', 1), ('fox', 1), ('jumped', 1), ('over', 1), ('the', 1), 
# ('lazy', 1), ('grey', 1), ('dogs', 1), ('that', 1), ('is', 1), ('one', 1), ('small', 1), ('step', 1), 
# ('for', 1), ('a', 1), ('man', 1), ('but', 1), ('one', 1), ('giant', 1), ('leap', 1), ('for', 1), ('mankind', 1)]
# 
# order is not important
# output = {'a': [1],'brown': [1],'but': [1],'dogs': [1],'for': [1, 1],'fox': [1],'giant': [1],'grey': [1],'is': [1],
# 'jumped': [1],'lazy': [1],'leap': [1],'man': [1],'mankind': [1],'one': [1, 1],'over': [1],'quick': [1],'small': [1],
# 'step': [1], 'that': [1],'the': [1, 1]}
combiner(mapper("documents.txt"))
# or, test both:
# combiner(mapper("documents.txt"))
{'the': [1, 1],
 'quick': [1],
 'brown': [1],
 'fox': [1],
 'jumped': [1],
 'over': [1],
 'lazy': [1],
 'grey': [1],
 'dogs': [1],
 'that': [1],
 'is': [1],
 'one': [1, 1],
 'small': [1],
 'step': [1],
 'for': [1, 1],
 'a': [1],
 'man': [1],
 'but': [1],
 'giant': [1],
 'leap': [1],
 'mankind': [1]}
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
Q3: Reducer function
Write a reducer function that takes a word and corresponding list of counts as input and outputs a tuple of (key, value), such that the key is the word and value is the total count for that word.

# reducer(word, listOfCounts) takes a word and corresponding list of counts as input and outputs a tuple with:
# the first element as the word
# second element as the total count which is the sum of counts in the given list.
​
​
​
def reducer(word, listOfCounts):
    
    ###
    ### YOUR CODE HERE
    ###  
    count = 0
    for num in listOfCounts: 
        count += num
​
    return((word, count))    
# Example 
# 
# input: ('for', [1, 1])
#
# output: ('for', 2)
reducer('for', [1, 1])
('for', 2)
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
Q4: Execute function
Write the wrapper execute function that uses the mapper, combiner and reducer functions above to calculate the frequency (counts) of the words across all the sentences sentences.

# execute(listOfDocuments) takes a list of sentences (strings) as input. 
# The function makes a call to the mapper function, sorts the output of the mapper function (by key). This sorted 
# output is then given as input to the combiner function, to get a dictionary of word and corresponding list of counts. 
# For each word in the dictionary, call the reducer to get the word and its total count. 
# The function returns a sorted list of tuples (sorted by first element) with:
# the first element as the word
# the second element as the total count
​
​
def execute(filename):
    
    ###
    ### YOUR CODE HERE
    ###   
    mlist = []
    mdict = combiner(mapper(filename))  
    #return(mdict)  
    for pair in mdict: 
        mlist.append((pair, mdict[pair]))
​
    #return(mlist)  
    rlist = [] 
    for tup in mlist: 
        rlist.append(reducer(tup[0], tup[1])) 
    
    
    #print(rlist.sort(key = lambda x: x[0]))
    return(sorted(rlist, key = lambda x: x[0]))
​
    
    
    
# Example 
# output: [('a', 1), ('brown', 1), ('but', 1), ('dogs', 1), ('for', 2), ('fox', 1), ('giant', 1), ('grey', 1), 
# ('is', 1), ('jumped', 1), ('lazy', 1), ('leap', 1), ('man', 1), ('mankind', 1), ('one', 2), ('over', 1),
# ('quick', 1), ('small', 1), ('step', 1), ('that', 1), ('the', 2)]
execute("documents.txt")
[('a', 1),
 ('brown', 1),
 ('but', 1),
 ('dogs', 1),
 ('for', 2),
 ('fox', 1),
 ('giant', 1),
 ('grey', 1),
 ('is', 1),
 ('jumped', 1),
 ('lazy', 1),
 ('leap', 1),
 ('man', 1),
 ('mankind', 1),
 ('one', 2),
 ('over', 1),
 ('quick', 1),
 ('small', 1),
 ('step', 1),
 ('that', 1),
 ('the', 2)]
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​
###
### AUTOGRADER TEST - DO NOT REMOVE
###
​

