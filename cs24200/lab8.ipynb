Jupyter NotebookLab8 Last Checkpoint: 10/31/2020 (autosaved)Python 3 [3.6]
Lab 8
K-Means Clustering
For this Lab, you can use the sklearn library in python. You should use plotnine library for making plots.

The documentation here is useful: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans

Note: The attribute .cluster_centers_ returns cluster centroids with the last column providing diagnostic information, so you can discard that column.

Part 1 (2 points)
Read data from the file "iris.csv". Create a scatter plot with feature 'petal_length' on the x axis and 'petal_width' on the y axis. Determine how many groups you think there are in the data based on the scatter plot and report below.

import numpy as np
from plotnine import *
from sklearn.cluster import KMeans
import pandas as pd
import matplotlib.pyplot as plt
import plotnine as p9
###
### YOUR CODE HERE
### 
​
iris = pd.read_csv('iris.csv') 
#print(iris.head())
plot = (p9.ggplot(iris, p9.aes(x='petal_length',y='petal_width')) + p9.geom_point()) 
plot

<ggplot: (-9223363285779062619)>
'There appear to be 3 groups present within the above scatter scatter plot from my observations.'
Part 2 (2+2+2+2+2 points)
For k = 1, 2, 3, 4, and 5 do the following:

Perform k-means clustering.
Create a scatter plot with feature 'petal_length' on x axis and feature 'petal_width' on y axis. For each scatter plot: i. Color each cluster with a different color. ii. Mark the centroids obtained after running the k-means algorithm as red stars.
Note: to get centroids, you must use the .cluster_centers attribute (see documentation). This will return a numpy array: use the first column as the x-coordinates of your centroids and second column as the y-coordinates.

For k = 1
###
### YOUR CODE HERE
### 
X = iris.iloc[:,[2,3]].values 
kmeans = KMeans(n_clusters=1) 
kmeans.fit(X) 
y_kmeans = kmeans.predict(X)  
​
plt.scatter(X[:,0], X[:,1], c=y_kmeans, cmap='viridis', alpha = 0.5)
centers = kmeans.cluster_centers_
plt.scatter(centers[:,0], centers[:, 1], c='red', alpha = 1, marker = '*')
​
<matplotlib.collections.PathCollection at 0x7f57f29812b0>

For k = 2
###
### YOUR CODE HERE
###
X = iris.iloc[:,[2,3]].values 
kmeans = KMeans(n_clusters=2) 
kmeans.fit(X) 
y_kmeans = kmeans.predict(X)  
​
plt.scatter(X[:,0], X[:,1], c=y_kmeans, cmap='viridis', alpha = 0.5)
centers = kmeans.cluster_centers_ 
plt.scatter(centers[:,0], centers[:, 1], c='red', alpha = 1, marker = '*')
<matplotlib.collections.PathCollection at 0x7f57f27cc748>

For k = 3
###
### YOUR CODE HERE
### 
X = iris.iloc[:,[2,3]].values 
kmeans = KMeans(n_clusters=3) 
kmeans.fit(X) 
y_kmeans = kmeans.predict(X)  
​
plt.scatter(X[:,0], X[:,1], c=y_kmeans,cmap='viridis', alpha = 0.5)
centers = kmeans.cluster_centers_ 
plt.scatter(centers[:,0], centers[:, 1], c='red', alpha = 1, marker = '*')
​
<matplotlib.collections.PathCollection at 0x7f57f27ae048>

For k = 4
###
### YOUR CODE HERE
### 
X = iris.iloc[:,[2,3]].values 
kmeans = KMeans(n_clusters=4) 
kmeans.fit(X) 
y_kmeans = kmeans.predict(X)  
​
plt.scatter(X[:,0], X[:,1], c=y_kmeans,cmap='viridis', alpha = 0.5)
centers = kmeans.cluster_centers_ 
plt.scatter(centers[:,0], centers[:, 1], c='red', alpha = 1, marker = '*')
​
<matplotlib.collections.PathCollection at 0x7f57f2704668>

For k = 5
###
### YOUR CODE HERE
### 
X = iris.iloc[:,[2,3]].values 
kmeans = KMeans(n_clusters=5) 
kmeans.fit(X) 
y_kmeans = kmeans.predict(X)  
​
plt.scatter(X[:,0], X[:,1], c=y_kmeans, cmap='viridis', alpha = 0.5)
centers = kmeans.cluster_centers_ 
plt.scatter(centers[:,0], centers[:, 1], c='red', alpha = 1, marker = '*')
​
<matplotlib.collections.PathCollection at 0x7f57f2489b38>

Part 3 (3 points)
Report the best choice for k based on your observations in part 2. How does this compare with the number of groups you choose in part 1?

The best k from part 2 is k = 5. This differs from my observation in part 1 because the increase in clusters in part 2 shows the true difference in clusters than in part 1.

